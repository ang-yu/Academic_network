
# V1: AY 08/04/19
# V2: AY 08/05/19
# V3: AY 08/09/19


# This is for matching the 1007 sociologists in our Top-40 programs sample with Twitter accounts (first determining whether they have Twitter)
# Before manually searching for their Twitter accounts, we first tried to do the matching it in some automatic ways.
# With the code below, we first searched the family names of the faculties in the followers of ASR's Twitter account,
# then we manually checked whether the resulting Twitter accounts are indeed handles of the real people in our sample
# Second, we used the same strategy with Twitter accounts that are followed by the ASAnews account for those who remained un-matched.
# Third, we tried to identify those who remain un-matched after the two steps above using data from our Pilot project, which contain already matched pairs and were collected in late June, 19 at the SICSS UCLA.
# After these three steps, we have 227 people who have identified Twitter accounts and 102 people who we know don't have an account.
# In the name_list_automatched file, the variable 'identified' = 1 if the person is successfully matched with a Twitter account 
# = 0  if we know the person does not have a Twitter account. Missing if we don't know whether this person has an account or not at this point. 

setwd("~/Downloads/Academic Network")

library("twitteR")
library("wordcloud")
library("tm")
library("rtweet")

consumer_key <- 'VPXR0O6pTFZvRWL95fKp736s4'
consumer_secret <- '5Bb1TDnsCcC1U0BfHfALucPAdugFmK6G9wgvyElPue9LDJo5Us'
access_token <- '1143210205854892032-L9WgZxHZzLGfqFr6n9J4gqP0bQBTrf'
access_secret <- '8DMaWUl34MDvPRXzLwnpMdwaUhaFe9HMBynUy637ZvWlr'

setup_twitter_oauth(consumer_key,
                    consumer_secret,
                    access_token,
                    access_secret)

token <- create_token(
  app = "Academic_network",
  consumer_key,
  consumer_secret,
  access_token,
  access_secret)

# First we use ASR followers to identify sociologists' accounts
asr_followers <- get_followers("asr_journal")  # 3780 followers of ASR as of 08/03/19

# get the profiles of all ASR followers
lookup_vector <- vector()

for (i in 1: length(asr_followers$user_id)) {
  
  tryCatch(lookup_vector[i] <- lookupUsers(asr_followers$user_id[i], includeNA=F),
           error=function(e){})
  
  if (i %% 900 == 0) {
    Sys.sleep(901)
  }
  
  # Some users cannot be found via their IDs for some unknown reason. And the rate limit is 900 every 15 min.  

}

# extract information from the downloaded list

description <- vector()
id <- vector()
name <- vector()
screenName <- vector()
url <- vector()

for (i in 1: length(lookup_vector)) {
  
  if (!is.null(lookup_vector[[i]]$id)){
    
    id[i] <- lookup_vector[[i]]$id
    name[i] <- lookup_vector[[i]]$name
    screenName[i] <- lookup_vector[[i]]$screenName
    description[i] <- lookup_vector[[i]]$description
    
    if (!identical(lookup_vector[[i]]$url, character(0))) {
      url[i] <- lookup_vector[[i]]$url
    }
    else {url[i] <- NA}
    
  }
  
  else {
    id[i] <- NA
    name[i] <- NA
    screenName[i] <- NA
    description[i] <- NA
    url[i] <- NA
    }
  
}


asr_followers_df <- as.data.frame(cbind(id, name, screenName, description, url), 
                                  stringsAsFactors=F)
asr_followers_df <- asr_followers_df[!is.na(asr_followers_df$name),]    # We got 3350 non-missing names 



name_list <- read.csv("~/Downloads/Academic Network/Top 40 Faculty List 2019 ASA Guide - Sheet1.csv", header=T, stringsAsFactors = F)
name_list <- name_list[,1:3]


# get the faculty surnames by first deleting the characters after the comma (like Jr., Dr.) and then extracting the part after the last space in their full name

Faculty.Name.Temp <- name_list$Faculty.Name
Faculty.Name.Temp <-gsub(",.*","",Faculty.Name.Temp)

surname <- vector()

for (i in 1:length(name_list$Faculty.Name)) {
  
  surname[i] <- tail(strsplit(Faculty.Name.Temp[i], split=" ")[[1]], 1)
  
}

name_list$surname <- surname

matched_id <- vector()
for (i in 1: length(name_list$surname)) {
  
  if (!identical(grep(name_list$surname[i], asr_followers_df$name, ignore.case=T), integer(0))) {
    
    matched_id[i] <- asr_followers_df$id[grep(name_list$surname[i], asr_followers_df$name, ignore.case=T)]
    
  }
  else {matched_id[i] <- NA}
  
}

name_list$matched_id <- matched_id 

name_list <- merge(name_list, asr_followers_df, by.x = "matched_id", by.y = "id", all.x = T)

write.csv(name_list[,c(2,3,4,6,8)], "name_list_asr_matched.csv", row.names = F)

# We got 422 faculty matched with someone in the ASR followers
# Then we manually check whether those matched ASR followers are indeed who we are looking for

matched_checked <- read.csv("name_list_asr_matched_checked.csv", stringsAsFactors = F)

sum(!is.na(matched_checked$identified))  # using ASR followers, we are able to identify exactly 100 sociologists' accounts. 


matched_checked <- matched_checked[,c("ID","identified")]

name_list <- merge(name_list, matched_checked, by = "ID")

write.csv(name_list, "temp_name_list.csv", row.names = F)
name_list <- read.csv("temp_name_list.csv")
name_list <- name_list[,c(1,3,4,5,7,10)]

# Then we try the same procedure with friends of ASA News

asa_friends <- get_friends("ASAnews") # 1732 friends of ASAnews as of 08/03/19

# get the profiles of all ASA friends
lookup_vector <- vector()

for (i in 1: length(asa_friends$user_id)) {
  
  tryCatch(lookup_vector[i] <- lookupUsers(asa_friends$user_id[i], includeNA=F),
           error=function(e){})
  
  if (i %% 900 == 0) {
    Sys.sleep(901)
  }
  
  # Some users cannot be found via their IDs for some unknown reason. And the rate limit is 900 every 15 min.  
  
}

# extract information from the downloaded list

description <- vector()
id <- vector()
name <- vector()
screenName <- vector()
url <- vector()

for (i in 1: length(lookup_vector)) {
  
  if (!is.null(lookup_vector[[i]]$id)){
    
    id[i] <- lookup_vector[[i]]$id
    name[i] <- lookup_vector[[i]]$name
    screenName[i] <- lookup_vector[[i]]$screenName
    description[i] <- lookup_vector[[i]]$description
    
    if (!identical(lookup_vector[[i]]$url, character(0))) {
      url[i] <- lookup_vector[[i]]$url
    }
    else {url[i] <- NA}
    
  }
  
  else {
    id[i] <- NA
    name[i] <- NA
    screenName[i] <- NA
    description[i] <- NA
    url[i] <- NA
  }
  
}


asa_friends_df <- as.data.frame(cbind(id, name, screenName, description, url), 
                                  stringsAsFactors=F)
asa_friends_df <- asa_friends_df[!is.na(asa_friends_df$name),]    # We got 1672 non-missing names 

# only keep the faculty names that remain un-identified
name_list_identified <- name_list[!is.na(name_list$identified),]
name_list_unidentified <- name_list[is.na(name_list$identified),]  # 907 sociologists un-identified
name_list_unidentified <- name_list_unidentified[, c(1:4)]

matched_id <- vector()
for (i in 1: length(name_list_unidentified$surname)) {
  
  if (!identical(grep(name_list_unidentified$surname[i], asa_friends_df$name, ignore.case=T), integer(0))) {
    
    matched_id[i] <- asa_friends_df$id[grep(name_list_unidentified$surname[i], asa_friends_df$name, ignore.case=T)]
    
  }
  else {matched_id[i] <- NA}
  
}


name_list_unidentified$matched_id <- matched_id 

name_list_unidentified <- merge(name_list_unidentified, asa_friends_df, by.x = "matched_id", by.y = "id", all.x = T)

write.csv(name_list_unidentified[,c(2,3,4,6,8)], "name_list_asa_matched.csv", row.names = F)

sum(!is.na(name_list_unidentified$screenName))
# We got 305 faculty matched with someone in the ASA friends
# Then we manually check whether those matched ASA friends are indeed who we are looking for

matched_checked <- read.csv("name_list_asa_matched_checked.csv", stringsAsFactors = F)

sum(!is.na(matched_checked$identified))  # using ASA friends, we are able to identify 75 sociologists' accounts. 

matched_checked <- matched_checked[,c("ID","identified")]

name_list_unidentified <- merge(name_list_unidentified, matched_checked, by = "ID")

name_list_unidentified <- name_list_unidentified[,-c(2,6,8,9)]

name_list <- rbind(name_list_identified, name_list_unidentified)
sum(!is.na(name_list$identified))   # Now, 175 identified. 

write.csv(name_list, "temp_name_list.csv", row.names = F)
name_list <- read.csv("temp_name_list.csv", stringsAsFactors = F)

name_list_identified.1 <- name_list[!is.na(name_list$identified),]
name_list_unidentified.1 <- name_list[is.na(name_list$identified),]
name_list_unidentified.1 <- name_list_unidentified.1[,-5]


# As a third step, we use the data from our Pilot project to supplement account identification.
# In the pilot project, we have already determined the existence of Twitter accouns and Twitter screennames for 342 sociologists.

warren_data <- read.csv("AP name list.xlsx - Warren AP Data.csv", stringsAsFactors = F)
sum(!is.na(warren_data$twitter_username))   # 141 out of 343 have Twitter accounts
(141/343)*1007   # by the same proportion, there should be about 414 sociologists in the large sample who have Twitter sccounts

warren_data <- warren_data[,c(2:6)]

name_list_unidentified.1_matched <- merge(name_list_unidentified.1, warren_data, by.x = "surname", by.y = "last_name", all.x = T)

# Then, again, we manually check and code the matched sociologists.
write.csv(name_list_unidentified.1_matched, "name_list_unidentified.1_matched.csv", row.names = F)

name_list_unidentified.1_matched_checked <- read.csv("name_list_unidentified.1_matched_checked.csv")

colnames(name_list_unidentified.1_matched_checked)[8] <- "screenName"

name_list_unidentified.1_matched_checked <- name_list_unidentified.1_matched_checked[,-c(6,7,9)]

name_list_automatched <- rbind(name_list_identified.1, name_list_unidentified.1_matched_checked)

name_list_automatched$screenName[is.na(name_list_automatched$identified) | name_list_automatched$identified==0] <- NA

table(name_list_automatched$identified)  # Now we have 227 Twitter accounts identified and 102 people who we know don't have an account

write.csv(name_list_automatched, "name_list_automatched.csv", row.names = F)

yet_to_be_done <- name_list_automatched[is.na(name_list_automatched$identified),]
write.csv(yet_to_be_done, "yet_to_be_done.csv", row.names = F)

#  will need to deal with duplications like Forrest Stuart.

# but note some people do share the same name:

# two Elizabeth Armstrong at Michigan and Princeton, 
# two John Logan at Wisconsin and Brown
# two Jennifer Hook at USC and PSU
# two Jennifer Lee at Indiana and Columbia


#### Then we manually searched for accounts for people in "yet_to_be_done" and merged the two files back together

yet <- read.csv("~/Downloads/Academic Network/yet_to_be_done_by four - yet_to_be_done_by four (3).csv", header=T, stringsAsFactors = F)

auto <- read.csv("~/Downloads/Academic Network/name_list_automatched - name_list_automatched.csv", header=T, stringsAsFactors = F)

yet <- yet[,1:5]
auto <- auto[!is.na(auto$identified),1:5]

merged <- rbind(auto, yet)

sum(!is.na(merged$screenName))

write.csv(merged, "top40_complete_080919.csv", row.names = F)

# Hence, at this point, we have identified 445 account out of 1005 people (note that we deleted two rows in this final step due to duplicates and mistaken inclusion)
